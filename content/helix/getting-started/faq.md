---
title: Frequently asked questions
weight: 2
aliases:
  - /docs/faq
---

## What makes Helix different?

We allow you to safely bring LLMs into your business by running models in your environment. This means you have zero data leakage risk and can develop your own fine-tuned LLM that remains your core IP.

## How hard is it to get started?

See [getting started](/docs/getting-started)!

You can start chatting with open source language models and generating images with Stable Diffusion XL by [creating a free account](https://app.tryhelix.ai) right now. Fine-tuning your own model on your own text or image data is as simple as drag’n’drop, and takes 3-10 minutes. You can then chat with and generate images from those fine-tuned models straight away, all using a familiar chat interface.


## My data is private, how can I train models on it securely without the data leaving my company’s infrastructure?

This is where Helix really shines – because the models are open source, you are free to fine-tune them on your own infrastructure, and Helix makes that as easy as half a day with a DevOps Engineer. Try it out on some of our sample data to get a feel for what it’s capable of, and then invite your DevOps Engineer to our [deployment guide](/docs/controlplane), and [shoot us an email](mailto:founders@helix.ml) at the same time.


## Can I integrate my models with my own apps or business apps once I’ve got it working?

Yes, we plan to offer OpenAI and Stability-SDK compatible APIs. These will be published on our documentation soon. [Get in touch with us](mailto:founders@helix.ml) for early access.